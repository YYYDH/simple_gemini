import streamlit as st
import base64
from google.generativeai import GenerativeModel, configure

# ------------------------------
# ğŸ” é¡µé¢å¯†ç ä¿æŠ¤
# ------------------------------
PAGE_PASSWORD = "112234ydh"

if "authenticated" not in st.session_state:
    st.session_state["authenticated"] = False

if not st.session_state["authenticated"]:
    st.title("ğŸ” è¯·è¾“å…¥è®¿é—®å¯†ç ")
    pwd = st.text_input("å¯†ç ", type="password")

    if pwd == PAGE_PASSWORD:
        st.session_state["authenticated"] = True
        st.rerun()
    else:
        if pwd != "":
            st.error("å¯†ç é”™è¯¯ï¼Œè¯·é‡è¯•")
    st.stop()  # ç»ˆæ­¢åç»­ä»£ç æ‰§è¡Œ

# ------------------------------
# é¡µé¢ & ä¾§è¾¹æ 
# ------------------------------
st.set_page_config(page_title="Gemini AI èŠå¤©", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– Gemini AI èŠå¤©åŠ©æ‰‹")
st.caption("ä¿ç•™ chat_inputï¼ˆç½®åº• + è‡ªåŠ¨é«˜åº¦ï¼‰ï¼Œå³ä¸‹è§’æµ®åŠ¨ ğŸ“ é™„ä»¶æŒ‰é’® â€” ä¸Šä¼ ä¸è‡ªåŠ¨å‘é€")

with st.sidebar:
    st.header("ğŸ”§ é…ç½®")

    # â­ é»˜è®¤ API KEY ï¼ˆå¯è¦†ç›–ï¼‰
    api_key = st.text_input(
        "Google Gemini API Key",
        type="password",
        value="AIzaSyD0HjQ57wfOtNxbbWqAlAIeRaQueZ9TjPk",
    )

    st.caption("API Key å¯ä» Google AI Studio è·å–")

    models = [
        "gemini-2.5-pro",
        "gemini-2.5-pro-latest",
        "gemini-1.5-pro",
        "gemini-1.5-flash",
        "gemini-pro"
    ]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", models, index=0)

    st.write("---")
    send_file_contents = st.checkbox(
        "å‘é€æ–‡ä»¶å†…å®¹ç»™ Geminiï¼ˆå°†æŠŠå°æ–‡ä»¶ base64 ç¼–ç éšæ¶ˆæ¯å‘é€ï¼‰",
        value=False
    )
    st.caption("å…³é—­åˆ™ä»…ä¿å­˜æ–‡ä»¶åä½œä¸ºå…ƒæ•°æ®ï¼›å¼€å¯ä¼šæŠŠæ–‡ä»¶ base64 ä¸€å¹¶å‘é€ï¼ˆæ³¨æ„éšç§ä¸å¤§å°ï¼‰")

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.pop("messages", None)
        st.session_state.pop("pending_attachments", None)
        st.experimental_rerun()

# åˆå§‹åŒ–çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "pending_attachments" not in st.session_state:
    st.session_state["pending_attachments"] = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for i, msg in enumerate(st.session_state["messages"]):
    with st.chat_message(msg["role"]):
        st.markdown(msg.get("content", ""))
        attachments = msg.get("attachments", [])
        if attachments:
            st.markdown("**é™„ä»¶ï¼š**")
            for j, att in enumerate(attachments):
                name = att.get("name")
                data = att.get("data")
                if data:
                    st.download_button(
                        label=f"ä¸‹è½½ {name}",
                        data=data,
                        file_name=name,
                        key=f"dl_{i}_{j}_{name}"
                    )
                else:
                    st.markdown(f"- {name}")

st.markdown("---")

# ------------------------------
# ğŸ“ æµ®åŠ¨ ChatGPT é£æ ¼é™„ä»¶æŒ‰é’®
# ------------------------------
files = st.file_uploader("", accept_multiple_files=True, key="floating_upload", label_visibility="collapsed")

st.markdown(
    """
    <style>
    div[data-testid="stFileUploader"] {
        position: fixed;
        right: 160px;
        bottom: 92px;
        z-index: 9999;
        width: 48px;
        height: 48px;
        padding: 0;
    }
    div[data-testid="stFileUploader"] > label { display: none !important; }
    div[data-testid="stFileUploader"] > div { height: 0px !important; overflow: visible !important; }
    div[data-testid="stFileUploader"]::before {
        content: "ğŸ“";
        display: flex;
        align-items: center;
        justify-content: center;
        width: 48px;
        height: 48px;
        border-radius: 50%;
        background: #ffffff;
        box-shadow: 0 6px 18px rgba(0,0,0,0.12);
        font-size: 22px;
        position: absolute;
        right: 0;
        bottom: 0;
        pointer-events: none;
    }
    div[data-testid="stFileUploader"] input[type="file"] {
        opacity: 0;
        width: 48px;
        height: 48px;
        position: absolute;
        right: 0;
        bottom: 0;
        z-index: 1000;
        cursor: pointer;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ä¿å­˜é™„ä»¶
if files:
    for f in (files if isinstance(files, list) else [files]):
        data = f.read()
        st.session_state["pending_attachments"].append({
            "name": f.name,
            "data": data,
            "type": getattr(f, "type", None),
            "size": len(data)
        })
    st.success("é™„ä»¶å·²æ·»åŠ ")

# æ˜¾ç¤º pending
if st.session_state["pending_attachments"]:
    cols = st.columns([0.9, 0.1])
    cols[0].markdown("**å¾…å‘é€é™„ä»¶ï¼š** " + ", ".join(a["name"] for a in st.session_state["pending_attachments"]))
    if cols[1].button("âœ– æ¸…é™¤é™„ä»¶"):
        st.session_state["pending_attachments"] = []

# ------------------------------
# èŠå¤©ï¼ˆå”¯ä¸€çš„ chat_inputï¼‰
# ------------------------------
if api_key:
    configure(api_key=api_key)
    model = GenerativeModel(selected_model)

    user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")
    if user_input:
        attachments_payload = []
        for att in st.session_state["pending_attachments"]:
            item = {"name": att["name"], "data": att["data"]}
            if send_file_contents:
                item["data_base64"] = base64.b64encode(att["data"]).decode("utf-8")
            attachments_payload.append(item)

        st.session_state["messages"].append({
            "role": "user",
            "content": user_input,
            "attachments": attachments_payload
        })
        with st.chat_message("user"):
            t = user_input
            if attachments_payload:
                t += "\n\n**é™„ä»¶:** " + ", ".join(a["name"] for a in attachments_payload)
            st.markdown(t)

        st.session_state["pending_attachments"] = []

        with st.chat_message("assistant"):
            placeholder = st.empty()
            full = ""
            try:
                response = model.generate_content(user_input, stream=True)
                for chunk in response:
                    if hasattr(chunk, "text") and chunk.text:
                        full += chunk.text
                        placeholder.markdown(full + "â–Œ")
                placeholder.markdown(full)
            except:
                # fallback
                r = model.generate_content(user_input)
                full = r.text if hasattr(r, "text") else str(r)
                placeholder.markdown(full)

        st.session_state["messages"].append({
            "role": "assistant",
            "content": full
        })
else:
    st.warning("è¯·å…ˆè¾“å…¥ API Key")
