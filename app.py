import streamlit as st
from google.generativeai import GenerativeModel, configure
import PIL.Image  # å¼•å…¥Pillowåº“ç”¨äºå¤„ç†å›¾ç‰‡
import io # ç”¨äºå¤„ç†äºŒè¿›åˆ¶æ•°æ®

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Gemini AI å¤šæ¨¡æ€èŠå¤©",
    page_icon="ğŸ¤–",
    layout="wide"
)

# æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ¤– Gemini AI å¤šæ¨¡æ€èŠå¤©åŠ©æ‰‹")
st.caption("åŸºäº Google Gemini APIï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡å’Œä»£ç æ–‡ä»¶è¾“å…¥")

# --- ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.header("ğŸ”§ é…ç½®")
    # 1. é…ç½® Gemini API Key
    try:
        # ä¼˜å…ˆä» Streamlit secrets è·å– API Key
        api_key = st.secrets["GEMINI_API_KEY"]
        st.success("å·²æˆåŠŸåŠ è½½ API Keyï¼")
    except (KeyError, FileNotFoundError):
        st.warning("æœªæ‰¾åˆ° secrets.toml ä¸­çš„ GEMINI_API_KEYï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ã€‚")
        api_key = st.text_input("è¯·è¾“å…¥ä½ çš„ Google Gemini API Key", type="password")

    st.caption("API Key å¯ä» [Google AI Studio](https://aistudio.google.com/) è·å–")

    # 2. æ¨¡å‹é€‰æ‹©
    models = [
        "gemini-1.5-pro-latest", # å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹
        "gemini-1.5-flash-latest", # å¿«é€Ÿçš„å¤šæ¨¡æ€æ¨¡å‹
        "gemini-pro-vision", # ä¸“é—¨çš„è§†è§‰æ¨¡å‹
        "gemini-pro" # çº¯æ–‡æœ¬æ¨¡å‹
    ]
    # è¿‡æ»¤æ‰ä¸å« 'vision' æˆ– '1.5' çš„æ¨¡å‹ï¼Œå› ä¸ºå®ƒä»¬ä¸æ”¯æŒå¤šæ¨¡æ€
    # selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", [m for m in models if 'vision' in m or '1.5' in m], index=0)
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", models, index=0)
    st.info("æç¤ºï¼šè¯·é€‰æ‹©æ”¯æŒå¤šæ¨¡æ€è¾“å…¥çš„æ¨¡å‹ï¼ˆå¦‚ gemini-1.5-pro, gemini-1.5-flashï¼‰ä»¥ä½¿ç”¨æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ã€‚")


    # 3. æ¸…ç©ºèŠå¤©è®°å½•æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.session_state.uploaded_files_info = {} # åŒæ—¶æ¸…ç©ºæ–‡ä»¶è®°å½•
        st.rerun()

# --- ä¸»èŠå¤©ç•Œé¢ ---

# åˆå§‹åŒ–èŠå¤©è®°å½• (æ›´å¤æ‚çš„ç»“æ„ä»¥æ”¯æŒå¤šæ¨¡æ€)
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        # æ ¹æ®æ¶ˆæ¯å†…å®¹ç±»å‹æ¥å†³å®šå¦‚ä½•å±•ç¤º
        if isinstance(msg["content"], str):
            st.markdown(msg["content"])
        elif isinstance(msg["content"], list):
            for part in msg["content"]:
                if part["type"] == "text":
                    st.markdown(part["data"])
                elif part["type"] == "image":
                    st.image(part["data"], caption=part.get("caption", "ä¸Šä¼ çš„å›¾ç‰‡"), use_column_width=True)
                elif part["type"] == "file":
                    st.info(f"ğŸ“„ å·²ä¸Šä¼ æ–‡ä»¶: `{part['name']}`")
                    # å¯é€‰ï¼šæ˜¾ç¤ºä»£ç æ–‡ä»¶å†…å®¹
                    # with st.expander(f"æŸ¥çœ‹ `{part['name']}` å†…å®¹"):
                    #     st.code(part['data'], language=part['name'].split('.')[-1])


# æ£€æŸ¥ API Key æ˜¯å¦é…ç½®
if api_key:
    # é…ç½® Gemini API
    try:
        configure(api_key=api_key)
        model = GenerativeModel(selected_model)
    except Exception as e:
        st.error(f"API Key é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä½ çš„ Key æ˜¯å¦æ­£ç¡®: {e}")
        st.stop() # é…ç½®å¤±è´¥åˆ™åœæ­¢è¿è¡Œ

    # --- æ–‡ä»¶ä¸Šä¼ å’ŒèŠå¤©è¾“å…¥æ¡† ---
    # ä½¿ç”¨ st.container å°†ä¸Šä¼ å’Œè¾“å…¥æ¡†åŒ…è£¹èµ·æ¥ï¼Œæ ·å¼æ›´ç»Ÿä¸€
    with st.container():
        # 1. æ–‡ä»¶ä¸Šä¼ å™¨
        uploaded_files = st.file_uploader(
            "âœ¨ ä¸Šä¼ é™„ä»¶ï¼ˆå›¾ç‰‡ã€ä»£ç ç­‰ï¼‰",
            accept_multiple_files=True,
            type=['jpg', 'jpeg', 'png', 'gif', 'py', 'txt', 'md', 'json', 'html', 'css', 'js']
        )
        # 2. ç”¨æˆ·è¾“å…¥æ¡†
        user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")

    if user_input or uploaded_files:
        # --- æ„é€ ç”¨æˆ·æ¶ˆæ¯ ---
        user_message_content = []
        display_message_content = []

        # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        if uploaded_files:
            for uploaded_file in uploaded_files:
                # è¯»å–æ–‡ä»¶å­—èŠ‚
                bytes_data = uploaded_file.getvalue()
                # åˆ¤æ–­æ–‡ä»¶ç±»å‹
                if uploaded_file.type.startswith('image/'):
                    try:
                        img = PIL.Image.open(io.BytesIO(bytes_data))
                        # æ·»åŠ åˆ° API è¯·æ±‚åˆ—è¡¨
                        user_message_content.append(img)
                        # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                        display_message_content.append({
                            "type": "image",
                            "data": img,
                            "caption": uploaded_file.name
                        })
                    except Exception as e:
                        st.error(f"æ— æ³•å¤„ç†å›¾ç‰‡æ–‡ä»¶ {uploaded_file.name}: {e}")
                else: # å…¶ä»–æ–‡ä»¶è§†ä¸ºæ–‡æœ¬/ä»£ç 
                    try:
                        file_content = bytes_data.decode('utf-8')
                        # æ„é€ ä¸€ä¸ªæ›´æ¸…æ™°çš„ä¸Šä¸‹æ–‡æç¤ºç»™æ¨¡å‹
                        formatted_content = f"è¿™æ˜¯ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ `{uploaded_file.name}` çš„å†…å®¹:\n\n```\n{file_content}\n```"
                        user_message_content.append(formatted_content)
                        # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                        display_message_content.append({
                            "type": "file",
                            "name": uploaded_file.name,
                            "data": file_content
                        })
                    except Exception as e:
                        st.error(f"æ— æ³•è¯»å–æ–‡ä»¶ {uploaded_file.name}: {e}")

        # å¤„ç†æ–‡æœ¬è¾“å…¥
        if user_input:
            user_message_content.append(user_input)
            display_message_content.append({"type": "text", "data": user_input})

        # --- æ˜¾ç¤ºå¹¶å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯ ---
        if display_message_content:
            st.session_state.messages.append({"role": "user", "content": display_message_content})
            with st.chat_message("user"):
                for part in display_message_content:
                    if part["type"] == "text":
                        st.markdown(part["data"])
                    elif part["type"] == "image":
                        st.image(part["data"], caption=part.get("caption", "ä¸Šä¼ çš„å›¾ç‰‡"), width=200) # é¢„è§ˆå›¾ç¼©å°
                    elif part["type"] == "file":
                        st.info(f"ğŸ“„ å·²ä¸Šä¼ æ–‡ä»¶: `{part['name']}`")


        # --- ç”Ÿæˆ AI å“åº” ---
        if user_message_content:
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                try:
                    # è°ƒç”¨ Gemini API (æµå¼å“åº”)
                    # æ³¨æ„ï¼šgenerate_content å¯ä»¥ç›´æ¥å¤„ç†åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡å¯¹è±¡çš„åˆ—è¡¨
                    response = model.generate_content(user_message_content, stream=True)
                    for chunk in response:
                        # æ£€æŸ¥ chunk æ˜¯å¦æœ‰ text å±æ€§ï¼Œä»¥åŠå¤„ç†å¯èƒ½çš„å®‰å…¨è®¾ç½®å¯¼è‡´çš„ç©ºå“åº”
                        if hasattr(chunk, 'text') and chunk.text:
                            full_response += chunk.text
                            message_placeholder.markdown(full_response + "â–Œ")
                    message_placeholder.markdown(full_response)
                    # å­˜å‚¨ AI å“åº”
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                    # st.rerun() # å¯ä»¥åœ¨æ¥æ”¶åˆ°å®Œæ•´å›å¤ååˆ·æ–°ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´è¾“å…¥æ¡†å¤±å»ç„¦ç‚¹ï¼Œçœ‹ä¸ªäººå–œå¥½
                except Exception as e:
                    st.error(f"API è°ƒç”¨å¤±è´¥ï¼š{e}")
                    # åŒæ ·å­˜å‚¨é”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
                    st.session_state.messages.append({"role": "assistant", "content": f"API è°ƒç”¨å¤±è´¥: {e}"})

else:
    # æœªè¾“å…¥ API Key æ—¶æç¤º
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ é…ç½®ä½ çš„ Google Gemini API Key ä»¥å¼€å§‹èŠå¤©")
    st.chat_input("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥ Gemini API Key", disabled=True)if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 4. å¤„ç†ç”¨æˆ·è¾“å…¥å’Œ AI å“åº”
if api_key:
    # é…ç½® Gemini API
    configure(api_key=api_key)
    model = GenerativeModel(selected_model)

    # ç”¨æˆ·è¾“å…¥æ¡†
    user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")
    if user_input:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯çŠ¶æ€
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # ç”Ÿæˆ AI å“åº”
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            # è°ƒç”¨ Gemini APIï¼ˆæµå¼å“åº”ï¼Œå®æ—¶æ˜¾ç¤ºï¼‰
            try:
                response = model.generate_content(user_input, stream=True)
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")  # åŠ è½½åŠ¨ç”»
                message_placeholder.markdown(full_response)  # æœ€ç»ˆå“åº”
                # ä¿å­˜ AI å“åº”åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"API è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ é…ç½®ä½ çš„ Google Gemini API Key ä»¥å¼€å§‹èŠå¤©")
    st.chat_input("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥ Gemini API Key", disabled=True)
