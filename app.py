import streamlit as st
from google.generativeai import GenerativeModel, configure
import google.generativeai as genai

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Gemini AI èŠå¤©",
    page_icon="ğŸ¤–",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ¤– Gemini AI èŠå¤©åŠ©æ‰‹ï¼ˆæ”¯æŒé™„ä»¶ï¼‰")
st.caption("æ”¯æŒæ–‡æœ¬ + å¤šç§æ–‡ä»¶ç±»å‹ï¼ˆå›¾ç‰‡ã€PDFã€æ–‡æ¡£ã€éŸ³é¢‘ã€è§†é¢‘ç­‰ï¼‰")


# ------------------------
# ä¾§è¾¹æ é…ç½®
# ------------------------
with st.sidebar:
    st.header("ğŸ”§ é…ç½®")
    api_key = st.text_input("Google Gemini API Key", type="password")

    models = [
        "gemini-2.5-pro",
        "gemini-2.5-pro-latest",
        "gemini-1.5-pro",
        "gemini-1.5-flash",
        "gemini-pro"
    ]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", models)

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.rerun()


# ------------------------
# åˆå§‹åŒ– SessionState
# ------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

if "pending_files" not in st.session_state:
    st.session_state.pending_files = []   # æœ¬æ¬¡å‡†å¤‡å‘é€çš„é™„ä»¶


# ------------------------
# æ˜¾ç¤ºèŠå¤©è®°å½•
# ------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

        # æ˜¾ç¤ºé™„ä»¶é¢„è§ˆ
        if "files" in msg:
            for f in msg["files"]:
                st.caption(f"ğŸ“ é™„ä»¶ï¼š{f['name']}")
                if f["mime"].startswith("image"):
                    st.image(f["data"], caption=f["name"])
                else:
                    st.download_button(
                        label=f"â¬‡ï¸ ä¸‹è½½ {f['name']}",
                        data=f["data"],
                        file_name=f["name"]
                    )


# ------------------------
# é™„ä»¶ä¸Šä¼ æŒ‰é’®ï¼ˆæ˜¾ç¤ºåœ¨è¾“å…¥æ¡†æ—è¾¹ï¼‰
# ------------------------
col1, col2 = st.columns([8, 2])

with col2:
    uploaded_files = st.file_uploader(
        "æ·»åŠ é™„ä»¶",
        accept_multiple_files=True,
        label_visibility="collapsed"
    )

if uploaded_files:
    for f in uploaded_files:
        st.session_state.pending_files.append(f)
    st.success(f"å·²æ·»åŠ  {len(uploaded_files)} ä¸ªæ–‡ä»¶")


# æ˜¾ç¤ºå½“å‰å¾…å‘é€çš„é™„ä»¶
if st.session_state.pending_files:
    st.info("ğŸ“ å¾…å‘é€é™„ä»¶ï¼š " + ", ".join([f.name for f in st.session_state.pending_files]))


# ------------------------
# èŠå¤©é€»è¾‘
# ------------------------
if api_key:
    configure(api_key=api_key)
    model = GenerativeModel(selected_model)

    with col1:
        user_input = st.chat_input("è¾“å…¥æ¶ˆæ¯...")

    if user_input or st.session_state.pending_files:
        # ---- å¤„ç†ç”¨æˆ·æ¶ˆæ¯å±•ç¤º ----
        user_message = {"role": "user", "content": user_input or "(å‘é€äº†é™„ä»¶)"}

        # å¦‚æœæœ‰é™„ä»¶ï¼ŒæŠŠé™„ä»¶åŠ å…¥æ¶ˆæ¯
        if st.session_state.pending_files:
            file_list = []
            for f in st.session_state.pending_files:
                file_list.append({
                    "name": f.name,
                    "mime": f.type,
                    "data": f.read()
                })
            user_message["files"] = file_list

        st.session_state.messages.append(user_message)

        # æ˜¾ç¤ºåˆ°ç•Œé¢
        with st.chat_message("user"):
            st.markdown(user_message["content"])
            if "files" in user_message:
                for f in user_message["files"]:
                    st.caption(f"ğŸ“ é™„ä»¶ï¼š{f['name']}")
                    if f["mime"].startswith("image"):
                        st.image(f["data"])
                    else:
                        st.download_button(
                            label=f"â¬‡ï¸ ä¸‹è½½ {f['name']}",
                            data=f["data"],
                            file_name=f["name"]
                        )

        # ---- è°ƒç”¨ Geminiï¼Œæ„é€  content parts ----
        parts = []
        if user_input:
            parts.append(user_input)

        # é™„ä»¶åŠ å…¥ parts
        if st.session_state.pending_files:
            for f in st.session_state.pending_files:
                parts.append({
                    "mime_type": f.type,
                    "data": f.getvalue()
                })

        # æ¸…ç©ºå¾…å‘é€é™„ä»¶
        st.session_state.pending_files = []

        # ---- è°ƒç”¨ API ----
        with st.chat_message("assistant"):
            placeholder = st.empty()
            full_text = ""

            try:
                response = model.generate_content(parts, stream=True)
                for chunk in response:
                    if chunk.text:
                        full_text += chunk.text
                        placeholder.markdown(full_text + "â–Œ")
                placeholder.markdown(full_text)

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_text
                })

            except Exception as e:
                st.error(f"API è°ƒç”¨å¤±è´¥ï¼š{e}")

else:
    st.chat_input("è¯·å…ˆé…ç½® API Key", disabled=True)
    st.warning("è¯·åœ¨å·¦ä¾§è¾“å…¥ Google Gemini API Keyã€‚")
